{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><a href=\"https://www.featuretools.com/\"><img src=\"img/featuretools-logo.png\" width=\"400\" height=\"200\" /></a></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> An Advanced Featuretools Approach with Premium Primitives</h2>\n",
    "<p>The following tutorial illustrates an advanced featuretools model for the NYC Taxi Trip Duration competition on Kaggle using premium primitives and our custom primitive API. You will need to download the following five files into a `data` folder in this repository.</p>\n",
    "\n",
    "<h2>Step 1: Load EntitySet </h2>\n",
    "\n",
    "For this example we will download a pre-built EntiySet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import featuretools as ft\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "es = ft.entityset.read_entityset(\"s3://featurelabs-static/nyc_taxi_entityset\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With [graphviz installed](https://docs.featuretools.com/getting_started/install.html#installing-graphviz) we can generate a visualization of the EntitySet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "es.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Featuretools with Premium Primitives and Custom Primitives"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some premium primitives we can apply to this problem:\n",
    "\n",
    "* CityblockDistance - roughly, the distance from point A to point B while only traveling due North, East, South, or West.  This can be a better metric for distance than Haversine since cars cannot travel diagonally through a city block.\n",
    "* IsInGeoBox - returns True if a LatLong coordinate is found within a rectangle created using the supplied coordinates as opposite corners of the box.\n",
    "    * (40.62, -73.85), (40.70, -73.75) - Area around JFK Airport\n",
    "    * (40.76, -73.89), (40.78, -73.85) - Area around La Guardia Airport\n",
    "* IsFederalHoliday - returns True if the input time was during a federal holiday\n",
    "* PartOfDay - returns Morning, Afternoon, Evening, or Night based on input time\n",
    "* Bearing - the angle (in degrees) between the shortest path from point A to B and North."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from featuretools.primitives import CityblockDistance, IsInGeoBox, IsFederalHoliday, PartOfDay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from featuretools.primitives import make_trans_primitive\n",
    "from featuretools.variable_types import LatLong, Numeric\n",
    "\n",
    "def bearing(latlong1, latlong2):\n",
    "    lat1 = np.array([x[0] for x in latlong1])\n",
    "    lon1 = np.array([x[1] for x in latlong1])\n",
    "    lat2 = np.array([x[0] for x in latlong2])\n",
    "    lon2 = np.array([x[1] for x in latlong2])\n",
    "    delta_lon = np.radians(lon2 - lon1)\n",
    "    lon1, lat1, lon2, lat2 = map(np.radians, [lon1, lat1, lon2, lat2])\n",
    "    x = np.cos(lat2) * np.sin(delta_lon)\n",
    "    y = np.cos(lat1) * np.sin(lat2) - np.sin(lat1) * np.cos(lat2) * np.cos(delta_lon)\n",
    "    return np.degrees(np.arctan2(x, y))\n",
    "\n",
    "Bearing = make_trans_primitive(function=bearing,\n",
    "                               input_types=[LatLong, LatLong],\n",
    "                               commutative=True,\n",
    "                               return_type=Numeric)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before calculating the features we need to specify the [cutoff time](https://docs.featuretools.com/automated_feature_engineering/handling_time.html#what-is-the-cutoff-time) for using data to calculate features for an individual trip. We'll use the time when the passenger was picked up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cutoff_time = es['trips'].df[['id', 'pickup_datetime']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_primitives = ['Sum', 'Mean', 'Median', 'Std', 'Count', 'Min', 'Max', 'Num_Unique', 'Skew']\n",
    "trans_primitives = [\"cityblock_distance\",\n",
    "                    IsInGeoBox((40.62, -73.85), (40.70, -73.75)),\n",
    "                    IsInGeoBox((40.76, -73.89), (40.78, -73.85)),\n",
    "                    \"is_federal_holiday\",\n",
    "                    \"part_of_day\",\n",
    "                    Bearing,\n",
    "                    \"Haversine\", \"Latitude\", \"Longitude\",\n",
    "                    'Day', 'Hour', 'Minute', 'Month', 'Weekday', 'Week', 'Is_weekend']\n",
    "\n",
    "# this allows us to create features that are conditioned on a second value before we calculate.\n",
    "es.add_interesting_values()\n",
    "\n",
    "# calculate feature_matrix using deep feature synthesis\n",
    "feature_matrix, features = ft.dfs(entityset=es,\n",
    "                                  target_entity=\"trips\",\n",
    "                                  trans_primitives=trans_primitives,\n",
    "                                  agg_primitives=agg_primitives,\n",
    "                                  drop_contains=['trips.test_data'],\n",
    "                                  verbose=True,\n",
    "                                  cutoff_time=cutoff_time,\n",
    "                                  approximate='36d',\n",
    "                                  max_depth=4)\n",
    "\n",
    "feature_matrix.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to encode the PartOfDay features so Xgboost can process them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_matrix, encoded_features = ft.encode_features(\n",
    "    feature_matrix=feature_matrix,\n",
    "    features=features,\n",
    "    to_encode=[\"PART_OF_DAY(pickup_datetime)\",\n",
    "               \"vendors.PART_OF_DAY(first_trips_time)\",\n",
    "               \"passenger_cnt.PART_OF_DAY(first_trips_time)\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Build the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>We need to retrieve our labels for the train dataset, so we should merge our current feature matrix with the original dataset. </p>\n",
    "\n",
    "<p>We use the `log` of the trip duration since that measure is better at distinguishing distances within the city</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train = encoded_matrix[encoded_matrix['test_data'] == False]\n",
    "X_train = X_train.drop(['test_data'], axis=1)\n",
    "labels = X_train['trip_duration']\n",
    "X_train = X_train.drop(['trip_duration'], axis=1)\n",
    "labels = np.log(labels.values + 1)\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train.values,\n",
    "                                                  labels,\n",
    "                                                  test_size=0.2,\n",
    "                                                  random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "dtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "dvalid = xgb.DMatrix(X_val, label=y_val)\n",
    "\n",
    "evals = [(dtrain, 'train'), (dvalid, 'valid')]\n",
    "\n",
    "xgb_params = {\n",
    "    \"min_child_weight\": 1, \"eta\": 0.166, \"colsample_bytree\": 0.4,\n",
    "    \"max_depth\": 9, \"subsample\": 1.0, \"lambda\": 57.93, \"booster\": \"gbtree\",\n",
    "    \"gamma\": 0.5, \"silent\": 1, \"eval_metric\": \"rmse\", \"objective\": \"reg:linear\"  \n",
    "}\n",
    "\n",
    "model = xgb.train(params=xgb_params, dtrain=dtrain, num_boost_round=227,\n",
    "                  evals=evals, early_stopping_rounds=60, maximize=False,\n",
    "                  verbose_eval=10)\n",
    "\n",
    "print('Modeling RMSLE %.5f' % model.best_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importance_dict = model.get_fscore()\n",
    "\n",
    "feature_names = X_train.columns.values\n",
    "fs = ['f%i' % i for i in range(len(feature_names))]\n",
    "f1 = pd.DataFrame({'f': list(feature_importance_dict.keys()),\n",
    "                   'importance': list(feature_importance_dict.values())})\n",
    "f2 = pd.DataFrame({'f': fs, 'feature_name': feature_names})\n",
    "feature_importance = pd.merge(f1, f2, how='right', on='f')\n",
    "feature_importance = feature_importance.fillna(0)\n",
    "feature_importance = feature_importance[['feature_name', 'importance']].sort_values(by='importance',\n",
    "                                                                      ascending=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>\n",
    "    <img src=\"https://www.featurelabs.com/wp-content/uploads/2017/12/logo.png\" alt=\"Featuretools\" />\n",
    "</p>\n",
    "\n",
    "Featuretools was created by the developers at [Feature Labs](https://www.featurelabs.com/). If building impactful data science pipelines is important to you or your business, please [get in touch](https://www.featurelabs.com/contact/)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
